# åç«¯æŠ€æœ¯å®ç°æ–¹æ¡ˆ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†åŸå¸‚å¤§è„‘ä¼ä¸šä¿¡æ¯å¤„ç†ç³»ç»Ÿåç«¯çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼ŒåŒ…æ‹¬FastAPIåº”ç”¨æ¶æ„ã€æœåŠ¡å±‚è®¾è®¡ã€AIæœåŠ¡é›†æˆå’Œæ•°æ®å¤„ç†æµç¨‹ã€‚

## ğŸ—ï¸ åº”ç”¨æ¶æ„è®¾è®¡

### é¡¹ç›®ç»“æ„
```
city_brain_system/
â”œâ”€â”€ main.py                 # åº”ç”¨å…¥å£
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py         # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ database.py         # æ•°æ®åº“é…ç½®
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ enterprise.py       # ä¼ä¸šæ¨¡å‹
â”‚   â”œâ”€â”€ address.py          # åœ°å€æ¨¡å‹
â”‚   â”œâ”€â”€ industry.py         # è¡Œä¸šæ¨¡å‹
â”‚   â””â”€â”€ data_quality.py     # æ•°æ®è´¨é‡æ¨¡å‹
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ enterprise.py       # ä¼ä¸šSchema
â”‚   â”œâ”€â”€ address.py          # åœ°å€Schema
â”‚   â””â”€â”€ common.py           # é€šç”¨Schema
â”œâ”€â”€ repositories/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py             # åŸºç¡€Repository
â”‚   â”œâ”€â”€ enterprise.py       # ä¼ä¸šRepository
â”‚   â””â”€â”€ data_quality.py     # æ•°æ®è´¨é‡Repository
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ enterprise.py       # ä¼ä¸šæœåŠ¡
â”‚   â”œâ”€â”€ ai_service.py       # AIæœåŠ¡
â”‚   â”œâ”€â”€ address.py          # åœ°å€æœåŠ¡
â”‚   â””â”€â”€ data_quality.py     # æ•°æ®è´¨é‡æœåŠ¡
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ enterprises.py      # ä¼ä¸šè·¯ç”±
â”‚   â”œâ”€â”€ addresses.py        # åœ°å€è·¯ç”±
â”‚   â”œâ”€â”€ ai_services.py      # AIæœåŠ¡è·¯ç”±
â”‚   â””â”€â”€ data_quality.py     # æ•°æ®è´¨é‡è·¯ç”±
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cache.py            # ç¼“å­˜å·¥å…·
â”‚   â”œâ”€â”€ logger.py           # æ—¥å¿—å·¥å…·
â”‚   â””â”€â”€ validators.py       # éªŒè¯å·¥å…·
â”œâ”€â”€ middleware/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth.py             # è®¤è¯ä¸­é—´ä»¶
â”‚   â”œâ”€â”€ cors.py             # CORSä¸­é—´ä»¶
â”‚   â””â”€â”€ logging.py          # æ—¥å¿—ä¸­é—´ä»¶
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_enterprises.py  # ä¼ä¸šæµ‹è¯•
    â””â”€â”€ test_ai_services.py  # AIæœåŠ¡æµ‹è¯•
```

## ğŸš€ FastAPI åº”ç”¨é…ç½®

### ä¸»åº”ç”¨å…¥å£ (main.py)
```python
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from contextlib import asynccontextmanager
import uvicorn

from config.settings import settings
from config.database import init_database, close_database
from utils.cache import init_cache, close_cache
from utils.logger import setup_logging
from middleware.logging import LoggingMiddleware
from routers import enterprises, addresses, industries, data_quality, ai_services

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    setup_logging()
    await init_database()
    await init_cache()
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†
    await close_database()
    await close_cache()

app = FastAPI(
    title="åŸå¸‚å¤§è„‘ä¼ä¸šä¿¡æ¯å¤„ç†ç³»ç»Ÿ",
    description="æ™ºèƒ½åŒ–ä¼ä¸šä¿¡æ¯æŸ¥è¯¢å’Œäº§ä¸šé“¾åˆ†æå¹³å°",
    version="2.0.0",
    docs_url="/docs" if settings.DEBUG else None,
    redoc_url="/redoc" if settings.DEBUG else None,
    lifespan=lifespan
)

# ä¸­é—´ä»¶é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(LoggingMiddleware)

# è·¯ç”±æ³¨å†Œ
app.include_router(
    enterprises.router, 
    prefix="/api/v1/enterprises", 
    tags=["enterprises"]
)
app.include_router(
    addresses.router, 
    prefix="/api/v1/addresses", 
    tags=["addresses"]
)
app.include_router(
    industries.router, 
    prefix="/api/v1/industries", 
    tags=["industries"]
)
app.include_router(
    data_quality.router, 
    prefix="/api/v1/data-quality", 
    tags=["data-quality"]
)
app.include_router(
    ai_services.router, 
    prefix="/api/v1/ai", 
    tags=["ai-services"]
)

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "version": "2.0.0"}

@app.get("/ready")
async def readiness_check():
    """å°±ç»ªæ£€æŸ¥ç«¯ç‚¹"""
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    # æ£€æŸ¥Redisè¿æ¥
    # æ£€æŸ¥å¤–éƒ¨APIè¿æ¥
    return {"status": "ready"}

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG,
        workers=settings.WORKERS if not settings.DEBUG else 1
    )
```

### é…ç½®ç®¡ç† (config/settings.py)
```python
from pydantic_settings import BaseSettings
from typing import List, Optional
import os

class Settings(BaseSettings):
    # åº”ç”¨é…ç½®
    APP_NAME: str = "åŸå¸‚å¤§è„‘ä¼ä¸šä¿¡æ¯å¤„ç†ç³»ç»Ÿ"
    VERSION: str = "2.0.0"
    DEBUG: bool = False
    HOST: str = "0.0.0.0"
    PORT: int = 9003
    WORKERS: int = 4
    
    # æ•°æ®åº“é…ç½®
    DATABASE_URL: str
    DATABASE_POOL_SIZE: int = 10
    DATABASE_MAX_OVERFLOW: int = 20
    DATABASE_POOL_TIMEOUT: int = 30
    
    # Redisé…ç½®
    REDIS_URL: str = "redis://localhost:6379/0"
    REDIS_POOL_SIZE: int = 10
    
    # AIæœåŠ¡é…ç½®
    BOCHAAI_API_KEY: str
    BOCHAAI_BASE_URL: str = "https://api.bochaai.com/v1"
    DEEPSEEK_API_KEY: str
    DEEPSEEK_BASE_URL: str = "https://api.deepseek.com"
    
    # å®‰å…¨é…ç½®
    SECRET_KEY: str
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    ALLOWED_ORIGINS: List[str] = ["*"]
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str = "INFO"
    LOG_FILE_PATH: Optional[str] = None
    LOG_ROTATION: str = "1 day"
    LOG_RETENTION: str = "30 days"
    
    # ç¼“å­˜é…ç½®
    CACHE_TTL: int = 3600  # 1å°æ—¶
    SEARCH_CACHE_TTL: int = 86400  # 24å°æ—¶
    
    # æ–‡ä»¶ä¸Šä¼ é…ç½®
    UPLOAD_DIR: str = "uploads"
    MAX_FILE_SIZE: int = 10 * 1024 * 1024  # 10MB
    ALLOWED_FILE_TYPES: List[str] = [".xlsx", ".xls", ".csv"]
    
    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()
```

## ğŸ—„ï¸ æ•°æ®æ¨¡å‹å®šä¹‰

### ä¼ä¸šæ¨¡å‹ (models/enterprise.py)
```python
from sqlalchemy import Column, BigInteger, String, Enum, Decimal, Date, Text, Boolean, TIMESTAMP, Index
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from config.database import Base
import enum

class EnterpriseType(str, enum.Enum):
    CUSTOMER = "customer"
    CHAIN_LEADER = "chain_leader"
    SUPPLIER = "supplier"
    OTHER = "other"

class EnterpriseStatus(str, enum.Enum):
    ACTIVE = "active"
    INACTIVE = "inactive"
    MERGED = "merged"
    DISSOLVED = "dissolved"

class DataSource(str, enum.Enum):
    MANUAL = "manual"
    WEB_SEARCH = "web_search"
    API = "api"
    IMPORT = "import"

class Enterprise(Base):
    __tablename__ = "enterprise"
    
    id = Column(BigInteger, primary_key=True, autoincrement=True, comment="ä¼ä¸šID")
    name = Column(String(255), nullable=False, comment="ä¼ä¸šåç§°")
    unified_social_credit_code = Column(String(32), unique=True, comment="ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç ")
    enterprise_type = Column(Enum(EnterpriseType), nullable=False, comment="ä¼ä¸šç±»å‹")
    status = Column(Enum(EnterpriseStatus), default=EnterpriseStatus.ACTIVE, comment="ä¼ä¸šçŠ¶æ€")
    registration_capital = Column(Decimal(15, 2), comment="æ³¨å†Œèµ„æœ¬")
    establishment_date = Column(Date, comment="æˆç«‹æ—¥æœŸ")
    business_scope = Column(Text, comment="ç»è¥èŒƒå›´")
    legal_representative = Column(String(100), comment="æ³•å®šä»£è¡¨äºº")
    contact_phone = Column(String(50), comment="è”ç³»ç”µè¯")
    contact_email = Column(String(100), comment="è”ç³»é‚®ç®±")
    website = Column(String(255), comment="å®˜æ–¹ç½‘ç«™")
    employee_count = Column(BigInteger, comment="å‘˜å·¥æ•°é‡")
    annual_revenue = Column(Decimal(15, 2), comment="å¹´è¥æ”¶")
    data_source = Column(Enum(DataSource), nullable=False, default=DataSource.MANUAL, comment="æ•°æ®æ¥æº")
    import_batch = Column(String(50), comment="å¯¼å…¥æ‰¹æ¬¡")
    confidence_score = Column(Decimal(3, 2), default=1.00, comment="æ•°æ®å¯ä¿¡åº¦")
    verified_at = Column(TIMESTAMP, comment="éªŒè¯æ—¶é—´")
    created_at = Column(TIMESTAMP, server_default=func.now(), comment="åˆ›å»ºæ—¶é—´")
    updated_at = Column(TIMESTAMP, server_default=func.now(), onupdate=func.now(), comment="æ›´æ–°æ—¶é—´")
    
    # å…³ç³»
    addresses = relationship("EnterpriseAddress", back_populates="enterprise", cascade="all, delete-orphan")
    source_relationships = relationship("EnterpriseRelationship", foreign_keys="EnterpriseRelationship.source_enterprise_id")
    target_relationships = relationship("EnterpriseRelationship", foreign_keys="EnterpriseRelationship.target_enterprise_id")
    
    # ç´¢å¼•
    __table_args__ = (
        Index('idx_enterprise_name', 'name'),
        Index('idx_enterprise_type', 'enterprise_type'),
        Index('idx_enterprise_credit_code', 'unified_social_credit_code'),
        Index('idx_enterprise_status', 'status'),
        Index('idx_enterprise_batch', 'import_batch'),
        Index('idx_enterprise_name_type', 'name', 'enterprise_type'),
        {'comment': 'ç»Ÿä¸€ä¼ä¸šä¿¡æ¯è¡¨'}
    )
    
    def __repr__(self):
        return f"<Enterprise(id={self.id}, name='{self.name}', type='{self.enterprise_type}')>"
```

### åœ°å€æ¨¡å‹ (models/address.py)
```python
from sqlalchemy import Column, BigInteger, String, Enum, Decimal, Boolean, TIMESTAMP, ForeignKey, Index
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from config.database import Base
import enum

class AddressType(str, enum.Enum):
    REGISTERED = "registered"
    OFFICE = "office"
    FACTORY = "factory"
    BRANCH = "branch"

class EnterpriseAddress(Base):
    __tablename__ = "enterprise_address"
    
    id = Column(BigInteger, primary_key=True, autoincrement=True, comment="åœ°å€ID")
    enterprise_id = Column(BigInteger, ForeignKey("enterprise.id", ondelete="CASCADE"), nullable=False, comment="ä¼ä¸šID")
    address_type = Column(Enum(AddressType), nullable=False, comment="åœ°å€ç±»å‹")
    province = Column(String(50), comment="çœä»½")
    city = Column(String(50), comment="åŸå¸‚")
    district = Column(String(50), comment="åŒºå¿")
    street = Column(String(100), comment="è¡—é“")
    detailed_address = Column(String(500), comment="è¯¦ç»†åœ°å€")
    postal_code = Column(String(10), comment="é‚®æ”¿ç¼–ç ")
    longitude = Column(Decimal(10, 7), comment="ç»åº¦")
    latitude = Column(Decimal(10, 7), comment="çº¬åº¦")
    data_source = Column(Enum(DataSource), nullable=False, comment="æ•°æ®æ¥æº")
    confidence_score = Column(Decimal(3, 2), default=1.00, comment="æ•°æ®å¯ä¿¡åº¦")
    verified_at = Column(TIMESTAMP, comment="éªŒè¯æ—¶é—´")
    is_primary = Column(Boolean, default=False, comment="æ˜¯å¦ä¸»è¦åœ°å€")
    created_at = Column(TIMESTAMP, server_default=func.now(), comment="åˆ›å»ºæ—¶é—´")
    updated_at = Column(TIMESTAMP, server_default=func.now(), onupdate=func.now(), comment="æ›´æ–°æ—¶é—´")
    
    # å…³ç³»
    enterprise = relationship("Enterprise", back_populates="addresses")
    
    # ç´¢å¼•
    __table_args__ = (
        Index('idx_address_enterprise_type', 'enterprise_id', 'address_type'),
        Index('idx_address_location', 'province', 'city', 'district'),
        Index('idx_address_coordinates', 'longitude', 'latitude'),
        Index('idx_address_enterprise_primary', 'enterprise_id', 'is_primary'),
        {'comment': 'ä¼ä¸šåœ°å€ä¿¡æ¯è¡¨'}
    )
    
    def __repr__(self):
        return f"<EnterpriseAddress(id={self.id}, enterprise_id={self.enterprise_id}, type='{self.address_type}')>"
```

## ğŸ”§ Repository æ¨¡å¼å®ç°

### åŸºç¡€ Repository (repositories/base.py)
```python
from abc import ABC, abstractmethod
from typing import List, Optional, Dict, Any, Type, TypeVar, Generic
from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy import and_, or_, desc, asc
from config.database import Base
from utils.logger import get_logger

T = TypeVar('T', bound=Base)
logger = get_logger(__name__)

class BaseRepository(Generic[T], ABC):
    def __init__(self, db: Session, model: Type[T]):
        self.db = db
        self.model = model
    
    async def create(self, obj_data: Dict[str, Any]) -> T:
        """åˆ›å»ºè®°å½•"""
        try:
            db_obj = self.model(**obj_data)
            self.db.add(db_obj)
            self.db.commit()
            self.db.refresh(db_obj)
            logger.info(f"Created {self.model.__name__} with id: {db_obj.id}")
            return db_obj
        except SQLAlchemyError as e:
            self.db.rollback()
            logger.error(f"Error creating {self.model.__name__}: {str(e)}")
            raise
    
    async def get_by_id(self, id: int) -> Optional[T]:
        """æ ¹æ®IDè·å–è®°å½•"""
        try:
            return self.db.query(self.model).filter(self.model.id == id).first()
        except SQLAlchemyError as e:
            logger.error(f"Error getting {self.model.__name__} by id {id}: {str(e)}")
            raise
    
    async def get_all(self, skip: int = 0, limit: int = 100, **filters) -> List[T]:
        """è·å–æ‰€æœ‰è®°å½•"""
        try:
            query = self.db.query(self.model)
            
            # åº”ç”¨è¿‡æ»¤å™¨
            if filters:
                query = self._apply_filters(query, filters)
            
            return query.offset(skip).limit(limit).all()
        except SQLAlchemyError as e:
            logger.error(f"Error getting all {self.model.__name__}: {str(e)}")
            raise
    
    async def update(self, id: int, obj_data: Dict[str, Any]) -> Optional[T]:
        """æ›´æ–°è®°å½•"""
        try:
            db_obj = await self.get_by_id(id)
            if db_obj:
                for field, value in obj_data.items():
                    if hasattr(db_obj, field):
                        setattr(db_obj, field, value)
                
                self.db.commit()
                self.db.refresh(db_obj)
                logger.info(f"Updated {self.model.__name__} with id: {id}")
            return db_obj
        except SQLAlchemyError as e:
            self.db.rollback()
            logger.error(f"Error updating {self.model.__name__} with id {id}: {str(e)}")
            raise
    
    async def delete(self, id: int) -> bool:
        """åˆ é™¤è®°å½•"""
        try:
            db_obj = await self.get_by_id(id)
            if db_obj:
                self.db.delete(db_obj)
                self.db.commit()
                logger.info(f"Deleted {self.model.__name__} with id: {id}")
                return True
            return False
        except SQLAlchemyError as e:
            self.db.rollback()
            logger.error(f"Error deleting {self.model.__name__} with id {id}: {str(e)}")
            raise
    
    async def count(self, **filters) -> int:
        """ç»Ÿè®¡è®°å½•æ•°é‡"""
        try:
            query = self.db.query(self.model)
            if filters:
                query = self._apply_filters(query, filters)
            return query.count()
        except SQLAlchemyError as e:
            logger.error(f"Error counting {self.model.__name__}: {str(e)}")
            raise
    
    def _apply_filters(self, query, filters: Dict[str, Any]):
        """åº”ç”¨è¿‡æ»¤å™¨"""
        for field, value in filters.items():
            if hasattr(self.model, field):
                if isinstance(value, list):
                    query = query.filter(getattr(self.model, field).in_(value))
                elif isinstance(value, dict):
                    # æ”¯æŒèŒƒå›´æŸ¥è¯¢
                    if 'gte' in value:
                        query = query.filter(getattr(self.model, field) >= value['gte'])
                    if 'lte' in value:
                        query = query.filter(getattr(self.model, field) <= value['lte'])
                    if 'like' in value:
                        query = query.filter(getattr(self.model, field).like(f"%{value['like']}%"))
                else:
                    query = query.filter(getattr(self.model, field) == value)
        return query
```

### ä¼ä¸š Repository (repositories/enterprise.py)
```python
from typing import List, Optional, Dict, Any
from sqlalchemy.orm import Session, joinedload
from sqlalchemy import and_, or_, func
from .base import BaseRepository
from models.enterprise import Enterprise, EnterpriseType, EnterpriseStatus
from models.address import EnterpriseAddress
from utils.logger import get_logger

logger = get_logger(__name__)

class EnterpriseRepository(BaseRepository[Enterprise]):
    def __init__(self, db: Session):
        super().__init__(db, Enterprise)
    
    async def search_by_name(self, name: str, fuzzy: bool = True, limit: int = 50) -> List[Enterprise]:
        """æ ¹æ®åç§°æœç´¢ä¼ä¸š"""
        try:
            query = self.db.query(Enterprise)
            
            if fuzzy:
                # æ¨¡ç³Šæœç´¢
                query = query.filter(
                    or_(
                        Enterprise.name.contains(name),
                        Enterprise.business_scope.contains(name)
                    )
                )
            else:
                # ç²¾ç¡®æœç´¢
                query = query.filter(Enterprise.name == name)
            
            return query.limit(limit).all()
        except Exception as e:
            logger.error(f"Error searching enterprises by name '{name}': {str(e)}")
            raise
    
    async def get_with_addresses(self, enterprise_id: int) -> Optional[Enterprise]:
        """è·å–ä¼ä¸šåŠå…¶åœ°å€ä¿¡æ¯"""
        try:
            return self.db.query(Enterprise)\
                .options(joinedload(Enterprise.addresses))\
                .filter(Enterprise.id == enterprise_id)\
                .first()
        except Exception as e:
            logger.error(f"Error getting enterprise with addresses for id {enterprise_id}: {str(e)}")
            raise
    
    async def get_by_type(self, enterprise_type: EnterpriseType, limit: int = 100) -> List[Enterprise]:
        """æ ¹æ®ä¼ä¸šç±»å‹è·å–ä¼ä¸šåˆ—è¡¨"""
        try:
            return self.db.query(Enterprise)\
                .filter(Enterprise.enterprise_type == enterprise_type)\
                .limit(limit)\
                .all()
        except Exception as e:
            logger.error(f"Error getting enterprises by type '{enterprise_type}': {str(e)}")
            raise
    
    async def get_chain_leaders_by_city(self, city: str) -> List[Enterprise]:
        """æ ¹æ®åŸå¸‚è·å–é“¾ä¸»ä¼ä¸š"""
        try:
            return self.db.query(Enterprise)\
                .join(EnterpriseAddress)\
                .filter(
                    and_(
                        Enterprise.enterprise_type == EnterpriseType.CHAIN_LEADER,
                        EnterpriseAddress.city == city
                    )
                )\
                .all()
        except Exception as e:
            logger.error(f"Error getting chain leaders by city '{city}': {str(e)}")
            raise
    
    async def get_statistics(self) -> Dict[str, Any]:
        """è·å–ä¼ä¸šç»Ÿè®¡ä¿¡æ¯"""
        try:
            total_count = self.db.query(func.count(Enterprise.id)).scalar()
            
            type_stats = self.db.query(
                Enterprise.enterprise_type,
                func.count(Enterprise.id).label('count')
            ).group_by(Enterprise.enterprise_type).all()
            
            status_stats = self.db.query(
                Enterprise.status,
                func.count(Enterprise.id).label('count')
            ).group_by(Enterprise.status).all()
            
            return {
                'total_count': total_count,
                'by_type': {stat.enterprise_type: stat.count for stat in type_stats},
                'by_status': {stat.status: stat.count for stat in status_stats}
            }
        except Exception as e:
            logger.error(f"Error getting enterprise statistics: {str(e)}")
            raise
    
    async def check_duplicate_by_name(self, name: str, exclude_id: Optional[int] = None) -> Optional[Enterprise]:
        """æ£€æŸ¥é‡å¤ä¼ä¸šåç§°"""
        try:
            query = self.db.query(Enterprise).filter(Enterprise.name == name)
            
            if exclude_id:
                query = query.filter(Enterprise.id != exclude_id)
            
            return query.first()
        except Exception as e:
            logger.error(f"Error checking duplicate enterprise name '{name}': {str(e)}")
            raise
    
    async def batch_update_data_source(self, enterprise_ids: List[int], data_source: str, batch_id: str) -> int:
        """æ‰¹é‡æ›´æ–°æ•°æ®æ¥æº"""
        try:
            updated_count = self.db.query(Enterprise)\
                .filter(Enterprise.id.in_(enterprise_ids))\
                .update({
                    'data_source': data_source,
                    'import_batch': batch_id
                }, synchronize_session=False)
            
            self.db.commit()
            logger.info(f"Batch updated {updated_count} enterprises with data_source: {data_source}")
            return updated_count
        except Exception as e:
            self.db.rollback()
            logger.error(f"Error batch updating enterprises: {str(e)}")
            raise
```

## ğŸ¤– AIæœåŠ¡é›†æˆ

### AIæœåŠ¡ (services/ai_service.py)
```python
import asyncio
import aiohttp
import json
import re
from typing import Dict, List, Optional, Any
from config.settings import settings
from utils.cache import cache_manager
from utils.logger import get_logger

logger = get_logger(__name__)

class AIService:
    def __init__(self):
        self.bochaai_api_key = settings.BOCHAAI_API_KEY
        self.deepseek_api_key = settings.DEEPSEEK_API_KEY
        self.bochaai_base_url = settings.BOCHAAI_BASE_URL
        self.deepseek_base_url = settings.DEEPSEEK_BASE_URL
        self.session = None
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30)
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    async def search_enterprise_info(self, enterprise_name: str) -> Dict[str, Any]:
        """è”ç½‘æœç´¢ä¼ä¸šä¿¡æ¯"""
        cache_key = f"enterprise_search:{enterprise_name}"
        cached_result = await cache_manager.get(cache_key)
        
        if cached_result:
            logger.info(f"Cache hit for enterprise search: {enterprise_name}")
            return cached_result
        
        search_query = f"{enterprise_name} ä¼ä¸šä¿¡æ¯ è¥æ”¶ å‘˜å·¥ åœ°å€ è”ç³»æ–¹å¼"
        
        try:
            headers = {
                "Authorization": f"Bearer {self.bochaai_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "query": search_query,
                "summary": True,
                "freshness": "year",
                "count": 10
            }
            
            async with self.session.post(
                f"{self.bochaai_base_url}/web-search",
                headers=headers,
                json=payload
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    
                    # ç¼“å­˜ç»“æœ24å°æ—¶
                    await cache_manager.set(cache_key, result, expire=settings.SEARCH_CACHE_TTL)
                    logger.info(f"Successfully searched enterprise info for: {enterprise_name}")
                    return result
                else:
                    error_text = await response.text()
                    logger.error(f"BochaAI API error {response.status}: {error_text}")
                    raise Exception(f"æœç´¢APIè°ƒç”¨å¤±è´¥: {response.status}")
                    
        except Exception as e:
            logger.error(f"Error searching enterprise info for {enterprise_name}: {str(e)}")
            raise
    
    async def extract_structured_info(self, search_results: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨LLMæå–ç»“æ„åŒ–ä¿¡æ¯"""
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¼ä¸šä¿¡æ¯æå–ä¸“å®¶ã€‚è¯·ä»æœç´¢ç»“æœä¸­æå–ä»¥ä¸‹ç»“æ„åŒ–ä¿¡æ¯ï¼š
        
        1. ä¼ä¸šåŸºæœ¬ä¿¡æ¯ï¼š
           - ä¼ä¸šå…¨ç§°
           - ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç 
           - æ³¨å†Œèµ„æœ¬
           - æˆç«‹æ—¶é—´
           - æ³•å®šä»£è¡¨äºº
           - ç»è¥èŒƒå›´
        
        2. ç»è¥ä¿¡æ¯ï¼š
           - å¹´è¥æ”¶
           - å‘˜å·¥æ•°é‡
           - ä¸»è¥ä¸šåŠ¡
           - è¡Œä¸šåˆ†ç±»
        
        3. åœ°å€ä¿¡æ¯ï¼š
           - æ³¨å†Œåœ°å€
           - åŠå…¬åœ°å€
           - çœå¸‚åŒºä¿¡æ¯
        
        4. è”ç³»ä¿¡æ¯ï¼š
           - è”ç³»ç”µè¯
           - é‚®ç®±åœ°å€
           - å®˜æ–¹ç½‘ç«™
        
        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œç¡®ä¿æ•°æ®å‡†ç¡®æ€§ã€‚å¦‚æœæŸäº›ä¿¡æ¯ä¸ç¡®å®šæˆ–ç¼ºå¤±ï¼Œè¯·æ ‡æ³¨ä¸ºnullã€‚
        """
        
        user_prompt = f"æœç´¢ç»“æœï¼š{json.dumps(search_results, ensure_ascii=False)}"
        
        try:
            headers = {
                "Authorization": f"Bearer {self.deepseek_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 2000
            }
            
            async with self.session.post(
                f"{self.deepseek_base_url}/chat/completions",
                headers=headers,
                json=payload
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    ai_content = result['choices'][0]['message']['content']
                    
                    # è§£æAIè¿”å›çš„JSON
                    structured_info = self._parse_ai_response(ai_content)
                    logger.info("Successfully extracted structured info from search results")
                    return structured_info
                else:
                    error_text = await response.text()
                    logger.error(f"DeepSeek API error {response.status}: {error_text}")
                    raise Exception(f"AIæå–APIè°ƒç”¨å¤±è´¥: {response.status}")
                    
        except Exception as e:
            logger.error(f"Error extracting structured info: {str(e)}")
            raise
    
    async def extract_enterprise_name(self, text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–ä¼ä¸šåç§°"""
        cache_key = f"extract_name:{hash(text)}"
        cached_result = await cache_manager.get(cache_key)
        
        if cached_result:
            return cached_result
        
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¼ä¸šåç§°æå–ä¸“å®¶ã€‚è¯·ä»ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ä¸­æå–ä¼ä¸šåç§°ã€‚
        
        è§„åˆ™ï¼š
        1. å¦‚æœæ‰¾åˆ°æ˜ç¡®çš„ä¼ä¸šåç§°ï¼Œè¯·ç›´æ¥è¿”å›ä¼ä¸šåç§°ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹
        2. ä¼ä¸šåç§°é€šå¸¸åŒ…å«"æœ‰é™å…¬å¸"ã€"è‚¡ä»½æœ‰é™å…¬å¸"ã€"é›†å›¢"ç­‰åç¼€
        3. å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¼ä¸šåç§°ï¼Œè¯·è¿”å›"æœªæ‰¾åˆ°"
        4. åªè¿”å›ä¸€ä¸ªæœ€å¯èƒ½çš„ä¼ä¸šåç§°
        """
        
        try:
            headers = {
                "Authorization": f"Bearer {self.deepseek_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                "temperature": 0.1,
                "max_tokens": 100
            }
            
            async with self.session.post(
                f"{self.deepseek_base_url}/chat/completions",
                headers=headers,
                json=payload
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    ai_content = result['choices'][0]['message']['content'].strip()
                    
                    enterprise_name = ai_content if ai_content != "æœªæ‰¾åˆ°" else None
                    
                    # ç¼“å­˜ç»“æœ1å°æ—¶
                    await cache_manager.set(cache_key, enterprise_name, expire=3600)
                    
                    logger.info(f"Extracted enterprise name: {enterprise_name}")
                    return enterprise_name
                else:
                    error_text = await response.text()
                    logger.error(f"DeepSeek API error {response.status}: {error_text}")
                    return None
                    
        except Exception as e:
            logger.error(f"Error extracting enterprise name: {str(e)}")
            return None
    
    async def generate_enterprise_summary(self, enterprise_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¼ä¸šä¿¡æ¯ç»“æ„åŒ–æ€»ç»“"""
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¼ä¸šåˆ†æä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„ä¼ä¸šä¿¡æ¯ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„ä¼ä¸šæ€»ç»“æŠ¥å‘Šã€‚
        
        æŠ¥å‘Šåº”åŒ…æ‹¬ï¼š
        1. ä¼ä¸šåŸºæœ¬æ¦‚å†µï¼ˆåç§°ã€ç±»å‹ã€æˆç«‹æ—¶é—´ã€æ³¨å†Œèµ„æœ¬ç­‰ï¼‰
        2. ç»è¥çŠ¶å†µåˆ†æï¼ˆè¥æ”¶è§„æ¨¡ã€å‘˜å·¥è§„æ¨¡ã€ä¸»è¥ä¸šåŠ¡ç­‰ï¼‰
        3. åœ°ç†ä½ç½®ä¿¡æ¯ï¼ˆæ³¨å†Œåœ°å€ã€ç»è¥åœ°å€ç­‰ï¼‰
        4. äº§ä¸šé“¾ä½ç½®åˆ†æï¼ˆæ‰€å±è¡Œä¸šã€äº§ä¸šå¤§è„‘å…³è”ç­‰ï¼‰
        5. è”ç³»æ–¹å¼ä¿¡æ¯
        
        è¯·ä½¿ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§ã€‚æŠ¥å‘Šåº”è¯¥ç»“æ„æ¸…æ™°ï¼Œä¾¿äºé˜…è¯»ã€‚
        """
        
        user_prompt = f"ä¼ä¸šä¿¡æ¯ï¼š{json.dumps(enterprise_data, ensure_ascii=False)}"
        
        try:
            headers = {
                "Authorization": f"Bearer {self.deepseek_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 1500
            }
            
            async with self.session.post(
                f"{self.deepseek_base_url}/chat/completions",
                headers=headers,
                json=payload
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    summary = result['choices'][0]['message']['content']
                    logger.info("Successfully generated enterprise summary")
                    return summary
                else:
                    error_text = await response.text()
                    logger.error(f"DeepSeek API error {response.status}: {error_text}")
                    raise Exception(f"ç”Ÿæˆæ€»ç»“APIè°ƒç”¨å¤±è´¥: {response.status}")
                    
        except Exception as e:
            logger.error(f"Error generating enterprise summary: {str(e)}")
            raise
    
    def _parse_ai_response(self, ai_content: str) -> Dict[str, Any]:
        """è§£æAIè¿”å›çš„JSONå†…å®¹"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            return json.loads(ai_content)
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', ai_content, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›åŸå§‹å†…å®¹
            logger.warning(f"Failed to parse AI response as JSON: {ai_content}")
            return {"raw_content": ai_content}

# åˆ›å»ºå…¨å±€AIæœåŠ¡å®ä¾‹
ai_service = AIService()
```

---

*æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0*
*æ›´æ–°æ—¶é—´ï¼š2025å¹´9æœˆ26æ—¥*