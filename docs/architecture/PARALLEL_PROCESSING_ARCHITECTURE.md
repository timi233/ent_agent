# å¹¶è¡Œå¤„ç†æ¶æ„è®¾è®¡

## ğŸ“‹ æ¦‚è¿°

åŸºäºç”¨æˆ·æä¾›çš„ç»†åŒ–å·¥ä½œæµç¨‹å›¾ï¼Œæœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†åŸå¸‚å¤§è„‘ä¼ä¸šä¿¡æ¯å¤„ç†ç³»ç»Ÿçš„å¹¶è¡Œå¤„ç†æ¶æ„è®¾è®¡ï¼Œå®ç°å¤šæ³³é“å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå’Œä¾èµ–ç®¡ç†ã€‚

## ğŸŠâ€â™‚ï¸ å¤šæ³³é“å¹¶è¡Œå¤„ç†æ¶æ„

### æµç¨‹æ¦‚è§ˆ
```mermaid
graph TB
    A[æ˜ç¡®çš„ä¼ä¸šåç§°] --> B[åœ¨æœ¬åœ°DBæœç´¢ä¼ä¸šä¸»ä½“è®°å½•]
    B --> C{è®°å½•æ˜¯å¦å­˜åœ¨?}
    C -->|å¦| D[ã€æ–°ä¼ä¸šå‘ç°ã€‘æµç¨‹<br/>å…¨é¢è”ç½‘æœç´¢<br/>ç»“æŸ]
    C -->|æ˜¯| E[é˜¶æ®µä¸€: å¹¶è¡Œä»»åŠ¡åˆ†å‘ä¸æ‰§è¡Œ]
    
    E --> F[æ³³é“A: åœ°å€/åŒºåŸŸ]
    E --> G[æ³³é“B: äº§ä¸š/åœ°ä½]
    E --> H[æ³³é“C: äººå‘˜è§„æ¨¡]
    E --> I[æ³³é“D: è¥æ”¶]
    E --> J[æ³³é“E: å•†æœº]
    E --> K[æ³³é“F: èµ„è®¯]
    
    F --> L[é˜¶æ®µäºŒ: åŒæ­¥ç­‰å¾…ä¸ä¾èµ–åˆ†æ]
    G --> L
    H --> M[é˜¶æ®µä¸‰: ç»“æœæ±‡æ€»]
    I --> M
    J --> M
    K --> M
    L --> N[è¾“å‡ºG: ç”Ÿæ€å®šä½]
    N --> M
    M --> O[æ•´åˆæ‰€æœ‰è¾“å‡ºç”Ÿæˆæœ€ç»ˆç»“æ„åŒ–æŠ¥å‘Š]
```

## ğŸ”§ æŠ€æœ¯å®ç°æ¶æ„

### æ ¸å¿ƒç»„ä»¶è®¾è®¡

#### 1. ä»»åŠ¡ç¼–æ’å™¨ (Task Orchestrator)
```python
# services/task_orchestrator.py
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

@dataclass
class TaskResult:
    task_id: str
    status: TaskStatus
    data: Any
    error: Optional[str] = None
    execution_time: Optional[float] = None
    timestamp: datetime = None

class ParallelTaskOrchestrator:
    def __init__(self):
        self.task_results: Dict[str, TaskResult] = {}
        self.task_dependencies: Dict[str, List[str]] = {}
        
    async def execute_enterprise_processing(self, enterprise_id: int, enterprise_name: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¼ä¸šä¿¡æ¯å¤„ç†çš„å®Œæ•´æµç¨‹
        """
        processing_context = {
            "enterprise_id": enterprise_id,
            "enterprise_name": enterprise_name,
            "start_time": datetime.now(),
            "stage": "initialization"
        }
        
        try:
            # é˜¶æ®µä¸€: å¹¶è¡Œä»»åŠ¡åˆ†å‘ä¸æ‰§è¡Œ
            stage1_results = await self._execute_stage1_parallel_tasks(processing_context)
            processing_context["stage1_results"] = stage1_results
            processing_context["stage"] = "stage1_completed"
            
            # é˜¶æ®µäºŒ: åŒæ­¥ç­‰å¾…ä¸ä¾èµ–åˆ†æ
            stage2_results = await self._execute_stage2_dependency_analysis(processing_context)
            processing_context["stage2_results"] = stage2_results
            processing_context["stage"] = "stage2_completed"
            
            # é˜¶æ®µä¸‰: ç»“æœæ±‡æ€»
            final_result = await self._execute_stage3_result_integration(processing_context)
            processing_context["final_result"] = final_result
            processing_context["stage"] = "completed"
            
            return {
                "status": "success",
                "processing_context": processing_context,
                "final_result": final_result,
                "execution_time": (datetime.now() - processing_context["start_time"]).total_seconds()
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "processing_context": processing_context,
                "execution_time": (datetime.now() - processing_context["start_time"]).total_seconds()
            }
    
    async def _execute_stage1_parallel_tasks(self, context: Dict[str, Any]) -> Dict[str, TaskResult]:
        """
        é˜¶æ®µä¸€: æ‰§è¡Œ6ä¸ªå¹¶è¡Œæ³³é“ä»»åŠ¡
        """
        enterprise_id = context["enterprise_id"]
        enterprise_name = context["enterprise_name"]
        
        # åˆ›å»º6ä¸ªå¹¶è¡Œä»»åŠ¡
        tasks = [
            self._execute_lane_a_address_region(enterprise_id, enterprise_name),
            self._execute_lane_b_industry_position(enterprise_id, enterprise_name),
            self._execute_lane_c_personnel_scale(enterprise_id, enterprise_name),
            self._execute_lane_d_revenue(enterprise_id, enterprise_name),
            self._execute_lane_e_business_opportunities(enterprise_id, enterprise_name),
            self._execute_lane_f_news_information(enterprise_id, enterprise_name)
        ]
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ•´ç†ç»“æœ
        lane_results = {}
        lane_names = ["lane_a", "lane_b", "lane_c", "lane_d", "lane_e", "lane_f"]
        
        for i, result in enumerate(results):
            lane_name = lane_names[i]
            if isinstance(result, Exception):
                lane_results[lane_name] = TaskResult(
                    task_id=lane_name,
                    status=TaskStatus.FAILED,
                    data=None,
                    error=str(result)
                )
            else:
                lane_results[lane_name] = result
        
        return lane_results
    
    async def _execute_stage2_dependency_analysis(self, context: Dict[str, Any]) -> Dict[str, TaskResult]:
        """
        é˜¶æ®µäºŒ: ç­‰å¾…æ³³é“Aå’ŒBå®Œæˆï¼Œæ‰§è¡Œäº§ä¸šå¤§è„‘ä¸äº§ä¸šé“¾å®šä½åˆ†æ
        """
        stage1_results = context["stage1_results"]
        
        # æ£€æŸ¥æ³³é“Aå’ŒBæ˜¯å¦æˆåŠŸå®Œæˆ
        lane_a_result = stage1_results.get("lane_a")
        lane_b_result = stage1_results.get("lane_b")
        
        if (lane_a_result and lane_a_result.status == TaskStatus.COMPLETED and
            lane_b_result and lane_b_result.status == TaskStatus.COMPLETED):
            
            # æ‰§è¡Œç”Ÿæ€å®šä½åˆ†æ
            ecosystem_analysis = await self._execute_ecosystem_positioning_analysis(
                lane_a_result.data,  # åŒºåŸŸä¿¡æ¯
                lane_b_result.data   # äº§ä¸šä¿¡æ¯
            )
            
            return {
                "ecosystem_positioning": TaskResult(
                    task_id="ecosystem_positioning",
                    status=TaskStatus.COMPLETED,
                    data=ecosystem_analysis,
                    timestamp=datetime.now()
                )
            }
        else:
            return {
                "ecosystem_positioning": TaskResult(
                    task_id="ecosystem_positioning",
                    status=TaskStatus.FAILED,
                    data=None,
                    error="æ³³é“Aæˆ–BæœªæˆåŠŸå®Œæˆï¼Œæ— æ³•æ‰§è¡Œç”Ÿæ€å®šä½åˆ†æ",
                    timestamp=datetime.now()
                )
            }
    
    async def _execute_stage3_result_integration(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        é˜¶æ®µä¸‰: æ•´åˆæ‰€æœ‰è¾“å‡ºï¼Œç”Ÿæˆæœ€ç»ˆç»“æ„åŒ–æŠ¥å‘Š
        """
        stage1_results = context["stage1_results"]
        stage2_results = context["stage2_results"]
        
        # æ”¶é›†æ‰€æœ‰æˆåŠŸçš„ç»“æœ
        integrated_data = {
            "enterprise_id": context["enterprise_id"],
            "enterprise_name": context["enterprise_name"],
            "processing_timestamp": datetime.now().isoformat(),
            "data_sources": {}
        }
        
        # æ•´åˆé˜¶æ®µä¸€ç»“æœ
        for lane_name, result in stage1_results.items():
            if result.status == TaskStatus.COMPLETED:
                integrated_data["data_sources"][lane_name] = {
                    "data": result.data,
                    "timestamp": result.timestamp.isoformat() if result.timestamp else None,
                    "execution_time": result.execution_time
                }
        
        # æ•´åˆé˜¶æ®µäºŒç»“æœ
        for analysis_name, result in stage2_results.items():
            if result.status == TaskStatus.COMPLETED:
                integrated_data["data_sources"][analysis_name] = {
                    "data": result.data,
                    "timestamp": result.timestamp.isoformat() if result.timestamp else None,
                    "execution_time": result.execution_time
                }
        
        # ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
        structured_report = await self._generate_structured_report(integrated_data)
        
        return {
            "integrated_data": integrated_data,
            "structured_report": structured_report,
            "data_completeness": self._calculate_data_completeness(stage1_results, stage2_results),
            "processing_summary": self._generate_processing_summary(stage1_results, stage2_results)
        }
    
    def _calculate_data_completeness(self, stage1_results: Dict[str, TaskResult], 
                                   stage2_results: Dict[str, TaskResult]) -> Dict[str, Any]:
        """
        è®¡ç®—æ•°æ®å®Œæ•´æ€§
        """
        total_tasks = len(stage1_results) + len(stage2_results)
        completed_tasks = 0
        
        for result in stage1_results.values():
            if result.status == TaskStatus.COMPLETED:
                completed_tasks += 1
        
        for result in stage2_results.values():
            if result.status == TaskStatus.COMPLETED:
                completed_tasks += 1
        
        completeness_score = completed_tasks / total_tasks if total_tasks > 0 else 0
        
        return {
            "total_tasks": total_tasks,
            "completed_tasks": completed_tasks,
            "completeness_score": completeness_score,
            "completeness_percentage": f"{completeness_score * 100:.1f}%"
        }
```

#### 2. æ³³é“ä»»åŠ¡å®ç°

##### æ³³é“A: åœ°å€/åŒºåŸŸä¿¡æ¯å¤„ç†
```python
async def _execute_lane_a_address_region(self, enterprise_id: int, enterprise_name: str) -> TaskResult:
    """
    æ³³é“A: åœ°å€/åŒºåŸŸä¿¡æ¯å¤„ç†
    """
    start_time = datetime.now()
    task_id = "lane_a_address_region"
    
    try:
        # 1. æŸ¥æœ¬åœ°åœ°å€
        local_address = await self.db_service.get_enterprise_address(enterprise_id)
        
        if local_address and not self._is_address_expired(local_address, years=1):
            # ä½¿ç”¨æœ¬åœ°åœ°å€
            result_data = {
                "source": "local",
                "address_info": local_address,
                "region_info": await self._extract_region_info(local_address)
            }
        else:
            # è”ç½‘æœç´¢åœ°å€
            search_result = await self.search_service.search_enterprise_address(enterprise_name)
            
            if search_result:
                # æ›´æ–°æ•°æ®åº“
                await self.db_service.update_enterprise_address(
                    enterprise_id, 
                    search_result,
                    update_time=datetime.now()
                )
                
                result_data = {
                    "source": "web_search",
                    "address_info": search_result,
                    "region_info": await self._extract_region_info(search_result)
                }
            else:
                result_data = {
                    "source": "none",
                    "address_info": None,
                    "region_info": None,
                    "error": "æ— æ³•è·å–åœ°å€ä¿¡æ¯"
                }
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.COMPLETED,
            data=result_data,
            execution_time=execution_time,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.FAILED,
            data=None,
            error=str(e),
            execution_time=execution_time,
            timestamp=datetime.now()
        )

def _is_address_expired(self, address_data: Dict[str, Any], years: int = 1) -> bool:
    """
    æ£€æŸ¥åœ°å€æ•°æ®æ˜¯å¦è¿‡æœŸ
    """
    if not address_data.get("updated_at"):
        return True
    
    updated_at = address_data["updated_at"]
    if isinstance(updated_at, str):
        updated_at = datetime.fromisoformat(updated_at)
    
    expiry_date = updated_at + timedelta(days=365 * years)
    return datetime.now() > expiry_date
```

##### æ³³é“B: äº§ä¸š/åœ°ä½ä¿¡æ¯å¤„ç†
```python
async def _execute_lane_b_industry_position(self, enterprise_id: int, enterprise_name: str) -> TaskResult:
    """
    æ³³é“B: äº§ä¸š/åœ°ä½ä¿¡æ¯å¤„ç†
    """
    start_time = datetime.now()
    task_id = "lane_b_industry_position"
    
    try:
        # 1. æŸ¥æœ¬åœ°äº§ä¸šä¿¡æ¯
        local_industry = await self.db_service.get_enterprise_industry(enterprise_id)
        
        if local_industry and not self._is_industry_expired(local_industry, years=1):
            # ä½¿ç”¨æœ¬åœ°äº§ä¸šä¿¡æ¯
            result_data = {
                "source": "local",
                "industry_info": local_industry,
                "position_analysis": await self._analyze_industry_position(local_industry)
            }
        else:
            # è”ç½‘æœç´¢äº§ä¸šä¿¡æ¯
            search_result = await self.search_service.search_enterprise_industry(enterprise_name)
            
            if search_result:
                # ä½¿ç”¨LLMåˆ†æäº§ä¸šåœ°ä½
                industry_analysis = await self.llm_service.analyze_industry_position(
                    enterprise_name, 
                    search_result
                )
                
                # æ›´æ–°æ•°æ®åº“
                await self.db_service.update_enterprise_industry(
                    enterprise_id,
                    {
                        "industry_info": search_result,
                        "position_analysis": industry_analysis,
                        "updated_at": datetime.now()
                    }
                )
                
                result_data = {
                    "source": "web_search",
                    "industry_info": search_result,
                    "position_analysis": industry_analysis
                }
            else:
                result_data = {
                    "source": "none",
                    "industry_info": None,
                    "position_analysis": None,
                    "error": "æ— æ³•è·å–äº§ä¸šä¿¡æ¯"
                }
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.COMPLETED,
            data=result_data,
            execution_time=execution_time,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.FAILED,
            data=None,
            error=str(e),
            execution_time=execution_time,
            timestamp=datetime.now()
        )
```

##### æ³³é“C: äººå‘˜è§„æ¨¡ä¿¡æ¯å¤„ç†
```python
async def _execute_lane_c_personnel_scale(self, enterprise_id: int, enterprise_name: str) -> TaskResult:
    """
    æ³³é“C: äººå‘˜è§„æ¨¡ä¿¡æ¯å¤„ç†
    """
    start_time = datetime.now()
    task_id = "lane_c_personnel_scale"
    
    try:
        # 1. æŸ¥æœ¬åœ°è§„æ¨¡ä¿¡æ¯
        local_scale = await self.db_service.get_enterprise_personnel_scale(enterprise_id)
        
        if local_scale and not self._is_scale_expired(local_scale, months=6):
            # ä½¿ç”¨æœ¬åœ°è§„æ¨¡ä¿¡æ¯
            result_data = {
                "source": "local",
                "personnel_scale": local_scale,
                "scale_category": self._categorize_scale(local_scale)
            }
        else:
            # è”ç½‘æœç´¢è§„æ¨¡ä¿¡æ¯
            search_result = await self.search_service.search_enterprise_scale(enterprise_name)
            
            if search_result:
                # ä½¿ç”¨LLMæå–ç»“æ„åŒ–è§„æ¨¡ä¿¡æ¯
                structured_scale = await self.llm_service.extract_personnel_scale(search_result)
                
                # æ›´æ–°æ•°æ®åº“
                await self.db_service.update_enterprise_personnel_scale(
                    enterprise_id,
                    structured_scale,
                    update_time=datetime.now()
                )
                
                result_data = {
                    "source": "web_search",
                    "personnel_scale": structured_scale,
                    "scale_category": self._categorize_scale(structured_scale)
                }
            else:
                result_data = {
                    "source": "none",
                    "personnel_scale": None,
                    "scale_category": None,
                    "error": "æ— æ³•è·å–äººå‘˜è§„æ¨¡ä¿¡æ¯"
                }
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.COMPLETED,
            data=result_data,
            execution_time=execution_time,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.FAILED,
            data=None,
            error=str(e),
            execution_time=execution_time,
            timestamp=datetime.now()
        )

def _is_scale_expired(self, scale_data: Dict[str, Any], months: int = 6) -> bool:
    """
    æ£€æŸ¥è§„æ¨¡æ•°æ®æ˜¯å¦è¿‡æœŸï¼ˆ6ä¸ªæœˆï¼‰
    """
    if not scale_data.get("updated_at"):
        return True
    
    updated_at = scale_data["updated_at"]
    if isinstance(updated_at, str):
        updated_at = datetime.fromisoformat(updated_at)
    
    expiry_date = updated_at + timedelta(days=30 * months)
    return datetime.now() > expiry_date

def _categorize_scale(self, scale_data: Dict[str, Any]) -> str:
    """
    æ ¹æ®äººå‘˜è§„æ¨¡è¿›è¡Œåˆ†ç±»
    """
    if not scale_data or not scale_data.get("employee_count"):
        return "æœªçŸ¥"
    
    employee_count = scale_data["employee_count"]
    
    if employee_count < 50:
        return "å°å¾®ä¼ä¸š"
    elif employee_count < 300:
        return "å°å‹ä¼ä¸š"
    elif employee_count < 1000:
        return "ä¸­å‹ä¼ä¸š"
    else:
        return "å¤§å‹ä¼ä¸š"
```

##### æ³³é“D: è¥æ”¶ä¿¡æ¯å¤„ç†
```python
async def _execute_lane_d_revenue(self, enterprise_id: int, enterprise_name: str) -> TaskResult:
    """
    æ³³é“D: è¥æ”¶ä¿¡æ¯å¤„ç†
    """
    start_time = datetime.now()
    task_id = "lane_d_revenue"
    
    try:
        # 1. æŸ¥æœ¬åœ°è¥æ”¶ä¿¡æ¯
        local_revenue = await self.db_service.get_enterprise_revenue(enterprise_id)
        
        if local_revenue and not self._is_revenue_expired(local_revenue, months=6):
            # ä½¿ç”¨æœ¬åœ°è¥æ”¶ä¿¡æ¯
            result_data = {
                "source": "local",
                "revenue_info": local_revenue,
                "revenue_trend": await self._analyze_revenue_trend(local_revenue)
            }
        else:
            # è”ç½‘æœç´¢è¥æ”¶ä¿¡æ¯
            search_result = await self.search_service.search_enterprise_revenue(enterprise_name)
            
            if search_result:
                # ä½¿ç”¨LLMæå–ç»“æ„åŒ–è¥æ”¶ä¿¡æ¯
                structured_revenue = await self.llm_service.extract_revenue_info(search_result)
                
                # æ›´æ–°æ•°æ®åº“
                await self.db_service.update_enterprise_revenue(
                    enterprise_id,
                    structured_revenue,
                    update_time=datetime.now()
                )
                
                result_data = {
                    "source": "web_search",
                    "revenue_info": structured_revenue,
                    "revenue_trend": await self._analyze_revenue_trend(structured_revenue)
                }
            else:
                result_data = {
                    "source": "none",
                    "revenue_info": None,
                    "revenue_trend": None,
                    "error": "æ— æ³•è·å–è¥æ”¶ä¿¡æ¯"
                }
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.COMPLETED,
            data=result_data,
            execution_time=execution_time,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.FAILED,
            data=None,
            error=str(e),
            execution_time=execution_time,
            timestamp=datetime.now()
        )
```

##### æ³³é“E: å•†æœºä¿¡æ¯å¤„ç†
```python
async def _execute_lane_e_business_opportunities(self, enterprise_id: int, enterprise_name: str) -> TaskResult:
    """
    æ³³é“E: å•†æœºä¿¡æ¯å¤„ç†ï¼ˆè¿‘3ä¸ªæœˆï¼‰
    """
    start_time = datetime.now()
    task_id = "lane_e_business_opportunities"
    
    try:
        # è”ç½‘æœç´¢è¿‘3ä¸ªæœˆçš„å•†æœºä¿¡æ¯
        search_result = await self.search_service.search_business_opportunities(
            enterprise_name,
            time_range="3months"
        )
        
        if search_result:
            # ä½¿ç”¨LLMåˆ†æå•†æœºä¿¡æ¯
            opportunities_analysis = await self.llm_service.analyze_business_opportunities(
                enterprise_name,
                search_result
            )
            
            result_data = {
                "source": "web_search",
                "opportunities": search_result,
                "analysis": opportunities_analysis,
                "search_period": "è¿‘3ä¸ªæœˆ"
            }
        else:
            result_data = {
                "source": "none",
                "opportunities": None,
                "analysis": None,
                "search_period": "è¿‘3ä¸ªæœˆ",
                "error": "æœªæ‰¾åˆ°ç›¸å…³å•†æœºä¿¡æ¯"
            }
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.COMPLETED,
            data=result_data,
            execution_time=execution_time,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.FAILED,
            data=None,
            error=str(e),
            execution_time=execution_time,
            timestamp=datetime.now()
        )
```

##### æ³³é“F: èµ„è®¯ä¿¡æ¯å¤„ç†
```python
async def _execute_lane_f_news_information(self, enterprise_id: int, enterprise_name: str) -> TaskResult:
    """
    æ³³é“F: èµ„è®¯ä¿¡æ¯å¤„ç†
    """
    start_time = datetime.now()
    task_id = "lane_f_news_information"
    
    try:
        # è”ç½‘æœç´¢æ–°é—»èµ„è®¯
        news_search_result = await self.search_service.search_enterprise_news(enterprise_name)
        
        if news_search_result:
            # ä½¿ç”¨LLMæ€»ç»“æ–°é—»ä¿¡æ¯
            news_summary = await self.llm_service.summarize_news(
                enterprise_name,
                news_search_result
            )
            
            result_data = {
                "source": "web_search",
                "news_articles": news_search_result,
                "summary": news_summary,
                "article_count": len(news_search_result.get("articles", []))
            }
        else:
            result_data = {
                "source": "none",
                "news_articles": None,
                "summary": None,
                "article_count": 0,
                "error": "æœªæ‰¾åˆ°ç›¸å…³æ–°é—»èµ„è®¯"
            }
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.COMPLETED,
            data=result_data,
            execution_time=execution_time,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        return TaskResult(
            task_id=task_id,
            status=TaskStatus.FAILED,
            data=None,
            error=str(e),
            execution_time=execution_time,
            timestamp=datetime.now()
        )
```

#### 3. ç”Ÿæ€å®šä½åˆ†æ
```python
async def _execute_ecosystem_positioning_analysis(self, region_info: Dict[str, Any], 
                                                industry_info: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ‰§è¡Œæœ¬åœ°äº§ä¸šå¤§è„‘ä¸äº§ä¸šé“¾å®šä½åˆ†æ
    """
    try:
        # è·å–æœ¬åœ°äº§ä¸šå¤§è„‘ä¿¡æ¯
        region_name = region_info.get("region_info", {}).get("city")
        industry_category = industry_info.get("industry_info", {}).get("category")
        
        if region_name and industry_category:
            # æŸ¥è¯¢æœ¬åœ°äº§ä¸šå¤§è„‘
            local_industry_brains = await self.db_service.get_industry_brains_by_region_and_industry(
                region_name, 
                industry_category
            )
            
            # æŸ¥è¯¢äº§ä¸šé“¾ä¿¡æ¯
            supply_chain_info = await self.db_service.get_supply_chain_info(industry_category)
            
            # ä½¿ç”¨LLMè¿›è¡Œç”Ÿæ€å®šä½åˆ†æ
            ecosystem_analysis = await self.llm_service.analyze_ecosystem_positioning(
                region_info=region_info,
                industry_info=industry_info,
                industry_brains=local_industry_brains,
                supply_chain_info=supply_chain_info
            )
            
            return {
                "region_name": region_name,
                "industry_category": industry_category,
                "local_industry_brains": local_industry_brains,
                "supply_chain_position": supply_chain_info,
                "ecosystem_analysis": ecosystem_analysis,
                "positioning_confidence": ecosystem_analysis.get("confidence_score", 0.0)
            }
        else:
            return {
                "error": "ç¼ºå°‘åŒºåŸŸæˆ–äº§ä¸šä¿¡æ¯ï¼Œæ— æ³•è¿›è¡Œç”Ÿæ€å®šä½åˆ†æ",
                "region_name": region_name,
                "industry_category": industry_category
            }
            
    except Exception as e:
        return {
            "error": f"ç”Ÿæ€å®šä½åˆ†æå¤±è´¥: {str(e)}",
            "region_info": region_info,
            "industry_info": industry_info
        }
```

#### 4. ç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆ
```python
async def _generate_structured_report(self, integrated_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç”Ÿæˆæœ€ç»ˆç»“æ„åŒ–æŠ¥å‘Šï¼ˆä¸éœ€è¦codeï¼Œåªå¯¹ç»“æ„è¿›è¡Œcheckï¼‰
    """
    try:
        # æ•°æ®ç»“æ„æ£€æŸ¥å’ŒéªŒè¯
        report_structure = {
            "enterprise_basic_info": {
                "name": integrated_data["enterprise_name"],
                "id": integrated_data["enterprise_id"],
                "processing_time": integrated_data["processing_timestamp"]
            },
            "data_completeness": {
                "address_region": self._check_data_structure(integrated_data, "lane_a"),
                "industry_position": self._check_data_structure(integrated_data, "lane_b"),
                "personnel_scale": self._check_data_structure(integrated_data, "lane_c"),
                "revenue_info": self._check_data_structure(integrated_data, "lane_d"),
                "business_opportunities": self._check_data_structure(integrated_data, "lane_e"),
                "news_information": self._check_data_structure(integrated_data, "lane_f"),
                "ecosystem_positioning": self._check_data_structure(integrated_data, "ecosystem_positioning")
            },
            "structured_content": {},
            "data_quality_score": 0.0,
            "recommendations": []
        }
        
        # ç»“æ„åŒ–å†…å®¹ç»„ç»‡
        data_sources = integrated_data.get("data_sources", {})
        
        for source_name, source_data in data_sources.items():
            if source_data and source_data.get("data"):
                report_structure["structured_content"][source_name] = {
                    "status": "available",
                    "data_type": type(source_data["data"]).__name__,
                    "timestamp": source_data.get("timestamp"),
                    "content_summary": self._summarize_content_structure(source_data["data"])
                }
            else:
                report_structure["structured_content"][source_name] = {
                    "status": "unavailable",
                    "reason": "æ•°æ®è·å–å¤±è´¥æˆ–ä¸ºç©º"
                }
        
        # è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†
        report_structure["data_quality_score"] = self._calculate_overall_quality_score(
            report_structure["data_completeness"]
        )
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        report_structure["recommendations"] = self._generate_improvement_recommendations(
            report_structure["data_completeness"],
            report_structure["data_quality_score"]
        )
        
        return report_structure
        
    except Exception as e:
        return {
            "error": f"ç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}",
            "integrated_data": integrated_data
        }

def _check_data_structure(self, integrated_data: Dict[str, Any], source_key: str) -> Dict[str, Any]:
    """
    æ£€æŸ¥æ•°æ®ç»“æ„å®Œæ•´æ€§
    """
    data_sources = integrated_data.get("data_sources", {})
    source_data = data_sources.get(source_key)
    
    if not source_data:
        return {
            "status": "missing",
            "completeness": 0.0,
            "issues": ["æ•°æ®æºç¼ºå¤±"]
        }
    
    data = source_data.get("data")
    if not data:
        return {
            "status": "empty",
            "completeness": 0.0,
            "issues": ["æ•°æ®ä¸ºç©º"]
        }
    
    # æ£€æŸ¥æ•°æ®ç»“æ„å®Œæ•´æ€§
    issues = []
    completeness_score = 1.0
    
    if isinstance(data, dict):
        if data.get("error"):
            issues.append(f"æ•°æ®è·å–é”™è¯¯: {data['error']}")
            completeness_score *= 0.3
        
        if data.get("source") == "none":
            issues.append("æœªèƒ½è·å–æœ‰æ•ˆæ•°æ®")
            completeness_score *= 0.5
        
        # æ£€æŸ¥å…³é”®å­—æ®µ
        required_fields = self._get_required_fields_by_source(source_key)
        missing_fields = []
        
        for field in required_fields:
            if not data.get(field):
                missing_fields.append(field)
        
        if missing_fields:
            issues.append(f"ç¼ºå°‘å…³é”®å­—æ®µ: {', '.join(missing_fields)}")
            completeness_score *= (1 - len(missing_fields) / len(required_fields))
    
    return {
        "status": "available" if completeness_score > 0.5 else "incomplete",
        "completeness": max(0.0, completeness_score),
        "issues": issues if issues else ["æ•°æ®ç»“æ„å®Œæ•´"]
    }

def _get_required_fields_by_source(self, source_key: str) -> List[str]:
    """
    æ ¹æ®æ•°æ®æºè·å–å¿…éœ€å­—æ®µåˆ—è¡¨
    """
    field_mapping = {
        "lane_a": ["address_info", "region_info"],
        "lane_b": ["industry_info", "position_analysis"],
        "lane_c": ["personnel_scale", "scale_category"],
        "lane_d": ["revenue_info", "revenue_trend"],
        "lane_e": ["opportunities", "analysis"],
        "lane_f": ["news_articles", "summary"],
        "ecosystem_positioning": ["ecosystem_analysis", "positioning_confidence"]
    }
    
    return field_mapping.get(source_key, [])

def _summarize_content_structure(self, data: Any) -> Dict[str, Any]:
    """
    æ€»ç»“å†…å®¹ç»“æ„
    """
    if isinstance(data, dict):
        return {
            "type": "object",
            "keys": list(data.keys()),
            "key_count": len(data.keys()),
            "has_nested_objects": any(isinstance(v, dict) for v in data.values()),
            "has_arrays": any(isinstance(v, list) for v in data.values())
        }
    elif isinstance(data, list):
        return {
            "type": "array",
            "length": len(data),
            "item_types": list(set(type(item).__name__ for item in data))
        }
    else:
        return {
            "type": type(data).__name__,
            "value_preview": str(data)[:100] if len(str(data)) > 100 else str(data)
        }

def _calculate_overall_quality_score(self, completeness_data: Dict[str, Any]) -> float:
    """
    è®¡ç®—æ•´ä½“æ•°æ®è´¨é‡è¯„åˆ†
    """
    if not completeness_data:
        return 0.0
    
    total_score = 0.0
    valid_sources = 0
    
    for source_name, source_completeness in completeness_data.items():
        if isinstance(source_completeness, dict) and "completeness" in source_completeness:
            total_score += source_completeness["completeness"]
            valid_sources += 1
    
    return total_score / valid_sources if valid_sources > 0 else 0.0

def _generate_improvement_recommendations(self, completeness_data: Dict[str, Any], 
                                        overall_score: float) -> List[str]:
    """
    ç”Ÿæˆæ”¹è¿›å»ºè®®
    """
    recommendations = []
    
    if overall_score < 0.6:
        recommendations.append("æ•´ä½“æ•°æ®å®Œæ•´æ€§è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®è·å–æµç¨‹")
    
    for source_name, source_data in completeness_data.items():
        if isinstance(source_data, dict):
            completeness = source_data.get("completeness", 0.0)
            issues = source_data.get("issues", [])
            
            if completeness < 0.5:
                recommendations.append(f"{source_name}: æ•°æ®å®Œæ•´æ€§ä¸è¶³ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®æº")
            
            if issues and "æ•°æ®è·å–é”™è¯¯" in str(issues):
                recommendations.append(f"{source_name}: å­˜åœ¨æ•°æ®è·å–é”™è¯¯ï¼Œå»ºè®®æ£€æŸ¥APIè¿æ¥")
    
    if not recommendations:
        recommendations.append("æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå»ºè®®å®šæœŸæ›´æ–°ä»¥ä¿æŒæ—¶æ•ˆæ€§")
    
    return recommendations
```

## ğŸ”„ APIæ¥å£è®¾è®¡

### ä¼ä¸šä¿¡æ¯å¤„ç†æ¥å£
```python
# api/enterprise_processing.py
from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import Dict, Any
from services.task_orchestrator import ParallelTaskOrchestrator

router = APIRouter(prefix="/api/v1/enterprise-processing", tags=["ä¼ä¸šä¿¡æ¯å¤„ç†"])

@router.post("/process/{enterprise_id}")
async def process_enterprise_information(
    enterprise_id: int,
    background_tasks: BackgroundTasks,
    force_refresh: bool = False
) -> Dict[str, Any]:
    """
    å¤„ç†ä¼ä¸šä¿¡æ¯çš„å®Œæ•´æµç¨‹
    """
    try:
        # è·å–ä¼ä¸šåŸºæœ¬ä¿¡æ¯
        enterprise = await enterprise_service.get_enterprise(enterprise_id)
        if not enterprise:
            raise HTTPException(status_code=404, detail="ä¼ä¸šä¸å­˜åœ¨")
        
        # åˆ›å»ºä»»åŠ¡ç¼–æ’å™¨
        orchestrator = ParallelTaskOrchestrator()
        
        # æ‰§è¡Œå¹¶è¡Œå¤„ç†æµç¨‹
        result = await orchestrator.execute_enterprise_processing(
            enterprise_id=enterprise_id,
            enterprise_name=enterprise["name"]
        )
        
        return {
            "status": "success",
            "message": "ä¼ä¸šä¿¡æ¯å¤„ç†å®Œæˆ",
            "data": result
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¤±è´¥: {str(e)}")

@router.get("/status/{enterprise_id}")
async def get_processing_status(enterprise_id: int) -> Dict[str, Any]:
    """
    è·å–ä¼ä¸šä¿¡æ¯å¤„ç†çŠ¶æ€
    """
    try:
        # è·å–å¤„ç†çŠ¶æ€ï¼ˆä»ç¼“å­˜æˆ–æ•°æ®åº“ï¼‰
        status = await processing_status_service.get_status(enterprise_id)
        
        return {
            "enterprise_id": enterprise_id,
            "status": status
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}")
```

## ğŸ“Š ç›‘æ§å’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPIs)
1. **å¹¶è¡Œå¤„ç†æ•ˆç‡**
   - 6ä¸ªæ³³é“ä»»åŠ¡çš„å¹³å‡æ‰§è¡Œæ—¶é—´
   - å¹¶è¡Œåº¦åˆ©ç”¨ç‡
   - ä»»åŠ¡æˆåŠŸç‡

2. **æ•°æ®è´¨é‡æŒ‡æ ‡**
   - æ•°æ®å®Œæ•´æ€§è¯„åˆ†
   - æ•°æ®æ—¶æ•ˆæ€§
   - é”™è¯¯ç‡ç»Ÿè®¡

3. **ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡**
   - APIå“åº”æ—¶é—´
   - ç¼“å­˜å‘½ä¸­ç‡
   - æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½

### ç›‘æ§å®ç°
```python
# monitoring/performance_monitor.py
import time
from typing import Dict, Any
from datetime import datetime

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {}
    
    async def record_lane_execution(self, lane_name: str, execution_time: float, status: str):
        """
        è®°å½•æ³³é“æ‰§è¡ŒæŒ‡æ ‡
        """
        if lane_name not in self.metrics:
            self.metrics[lane_name] = {
                "total_executions": 0,
                "successful_executions": 0,
                "total_time": 0.0,
                "average_time": 0.0,
                "success_rate": 0.0
            }
        
        metrics = self.metrics[lane_name]
        metrics["total_executions"] += 1
        metrics["total_time"] += execution_time
        
        if status == "completed":
            metrics["successful_executions"] += 1
        
        metrics["average_time"] = metrics["total_time"] / metrics["total_executions"]
        metrics["success_rate"] = metrics["successful_executions"] / metrics["total_executions"]
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """
        è·å–æ€§èƒ½æ‘˜è¦
        """
        return {
            "timestamp": datetime.now().isoformat(),
            "lane_metrics": self.metrics,
            "overall_performance": self._calculate_overall_performance()
        }
    
    def _calculate_overall_performance(self) -> Dict[str, Any]:
        """
        è®¡ç®—æ•´ä½“æ€§èƒ½æŒ‡æ ‡
        """
        if not self.metrics:
            return {"status": "no_data"}
        
        total_avg_time = sum(m["average_time"] for m in self.metrics.values()) / len(self.metrics)
        total_success_rate = sum(m["success_rate"] for m in self.metrics.values()) / len(self.metrics)
        
        return {
            "average_execution_time": total_avg_time,
            "overall_success_rate": total_success_rate,
            "active_lanes": len(self.metrics),
            "performance_grade": self._grade_performance(total_avg_time, total_success_rate)
        }
    
    def _grade_performance(self, avg_time: float, success_rate: float) -> str:
        """
        æ€§èƒ½ç­‰çº§è¯„å®š
        """
        if success_rate >= 0.95 and avg_time <= 5.0:
            return "ä¼˜ç§€"
        elif success_rate >= 0.90 and avg_time <= 10.0:
            return "è‰¯å¥½"
        elif success_rate >= 0.80 and avg_time <= 20.0:
            return "ä¸€èˆ¬"
        else:
            return "éœ€è¦ä¼˜åŒ–"
```

---

*æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0*
*æ›´æ–°æ—¶é—´ï¼š2025å¹´9æœˆ26æ—¥*